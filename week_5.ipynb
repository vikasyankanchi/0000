{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMcJO+LgCEAIxmag8yYrtjY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikasyankanchi/0000/blob/main/week_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjCG34NURskl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample raw data\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'Bob', None,'Alice'],\n",
        "    'Age': [25, None, 35, 30, 22,25],\n",
        "    'City': ['Delhi', 'Mumbai', 'Bangalore', 'Mumbai', 'Pune','Delhi']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Show original data\n",
        "print(\"Original Data:\")\n",
        "print(df)\n",
        "\n",
        "# 1. Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# 2. Remove rows with missing names\n",
        "df = df.dropna(subset=['Name'])\n",
        "\n",
        "# 3. Fill missing age with the mean\n",
        "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
        "\n",
        "print(\"\\nCleaned Data:\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Check structure and completeness\n",
        "df.info()\n",
        "\n",
        "# Summary statistics\n",
        "df.describe(include='all')\n",
        "\n",
        "# Check for duplicates\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "0KEUOF1fSTyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'ID': [1, 2, 2, 4, 5,2],\n",
        "    'Age': [25, 30, 30, -5, 200,30],\n",
        "    'Gender': ['Male', 'male', 'Male', 'F', 'Unknown','male'],\n",
        "    'Salary': [4000, None, 4000, 5000, -3000,None]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "QX73qLt0SUxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()          # Count duplicates\n",
        "df[df.duplicated()]"
      ],
      "metadata": {
        "id": "bm-OrV9kSZcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use describe to find extreme values\n",
        "print(df['Age'].describe())\n",
        "\n",
        "# Use boxplot for visual outliers\n",
        "import matplotlib.pyplot as plt\n",
        "df['Age'].plot.box()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N_DkLsuLSbpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for inconsistent gender entries\n",
        "print(df['Gender'].value_counts())\n",
        "\n",
        "# Fix known inconsistencies\n",
        "df['Gender'] = df['Gender'].replace({'male': 'Male', 'F': 'Female', 'Unknown': None})\n",
        "\n",
        "# Invalid salary (e.g., negative)\n",
        "print(df[df['Salary'] < 0])"
      ],
      "metadata": {
        "id": "G9tYY-rBScio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "rgjKkvKQSfRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data with missing values\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', None, 'Eve'],\n",
        "    'Age': [25, None, 30, 22],\n",
        "    'City': ['Delhi', 'Mumbai', 'Bangalore', None]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Use .info() to check non-null values\n",
        "df.info()"
      ],
      "metadata": {
        "id": "Z80FLM1RSheR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isna())"
      ],
      "metadata": {
        "id": "AlZfMN4iSjvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count missing values per column\n",
        "print(df.isna().sum())"
      ],
      "metadata": {
        "id": "zoe5RWK6Sl9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "data = pd.Series([160, 162, 158, 165, 161, 250])  # height in cm\n",
        "\n",
        "# Boxplot\n",
        "plt.boxplot(data)\n",
        "plt.title(\"Univariate Outlier Detection - Boxplot\")\n",
        "plt.show()\n",
        "\n",
        "# IQR method\n",
        "Q1 = data.quantile(0.25)\n",
        "Q3 = data.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers = data[(data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))]\n",
        "print(\"Outliers:\", outliers.values)"
      ],
      "metadata": {
        "id": "eOxZRjj8Spq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "height = np.array([160, 162, 158, 165, 161, 250])\n",
        "weight = np.array([55, 60, 54, 63, 59, 80])\n",
        "\n",
        "plt.scatter(height, weight)\n",
        "plt.xlabel(\"Height (cm)\")\n",
        "plt.ylabel(\"Weight (kg)\")\n",
        "plt.title(\"Bivariate Outlier Detection - Scatter Plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AkWV98LaSqgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dates = pd.date_range(start='2023-01-01', periods=12, freq='M')\n",
        "sales = pd.Series([200, 210, 205, 220, 215, 800, 225, 230, 240, 235,200, 245], index=dates)\n",
        "\n",
        "sales.plot(marker='o', title=\"Time Series Outlier Detection\")\n",
        "plt.show()\n",
        "\n",
        "# Simple detection: mean Â± 3*std\n",
        "mean = sales.mean()\n",
        "std = sales.std()\n",
        "outliers = sales[(sales > mean + 3*std) | (sales < mean - 3*std)]\n",
        "print(\"Outliers in time series:\\n\", outliers)"
      ],
      "metadata": {
        "id": "VDnlXw4OStCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.Series([5, 6, 7, 8, 100])  # Example data\n",
        "\n",
        "# Capping at 5th and 95th percentiles\n",
        "lower_cap = data.quantile(0.05)\n",
        "upper_cap = data.quantile(0.95)\n",
        "\n",
        "capped_data = data.clip(lower=lower_cap, upper=upper_cap)\n",
        "print(capped_data)"
      ],
      "metadata": {
        "id": "zyN2jWEpSwtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data = pd.Series([10, 12, 15, 20, 200])\n",
        "log_data = np.log(data)\n",
        "print(log_data)"
      ],
      "metadata": {
        "id": "cTXEcKfWSzI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = data.quantile(0.25)\n",
        "Q3 = data.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Keep only non-outliers\n",
        "filtered_data = data[(data >= (Q1 - 1.5 * IQR)) & (data <= (Q3 + 1.5 * IQR))]\n",
        "print(filtered_data)"
      ],
      "metadata": {
        "id": "AXyyHVmLS1cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Dataset A: Customer basic info\n",
        "data_a = {\n",
        "    'Customer_ID': [101, 102, 103],\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [25, 30, 35]\n",
        "}\n",
        "df_a = pd.DataFrame(data_a)\n",
        "\n",
        "# Dataset B: Customer address info\n",
        "data_b = {\n",
        "    'Customer_ID': [101, 102, 104],  # Note: ID 104 not in Dataset A\n",
        "    'Address': ['New York', 'Los Angeles', 'Chicago']\n",
        "}\n",
        "df_b = pd.DataFrame(data_b)\n",
        "\n",
        "print(\"Dataset A:\")\n",
        "print(df_a)\n",
        "print(\"\\nDataset B:\")\n",
        "print(df_b)\n",
        "\n",
        "# ----- Adding Attributes (Merge Columns) -----\n",
        "# Merge on Customer_ID to add Address to Dataset A\n",
        "df_merge = pd.merge(df_a, df_b, on='Customer_ID', how='left')\n",
        "print(\"\\nAfter Adding Attributes (Address column):\")\n",
        "print(df_merge)\n",
        "\n",
        "# ----- Adding Data Objects (Adding new rows) -----\n",
        "# Find rows in Dataset B not in Dataset A\n",
        "df_new_customers = df_b[~df_b['Customer_ID'].isin(df_a['Customer_ID'])]\n",
        "\n",
        "# Create full info for new customers (for simplicity, fill missing columns)\n",
        "df_new_customers = df_new_customers.assign(Name=['David'], Age=[28])\n",
        "\n",
        "# Append the new rows\n",
        "df_final = pd.concat([df_merge, df_new_customers], ignore_index=True)\n",
        "print(\"\\nAfter Adding Data Objects (new customers):\")\n",
        "print(df_final)"
      ],
      "metadata": {
        "id": "cyUKGsX4S3u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ---- Sample Dataset ----\n",
        "data = {\n",
        "    'Customer_ID': [1, 2, 3, 4, 5, 6],\n",
        "    'Age': [25, 30, 45, 40, 35, 50],\n",
        "    'Annual_Income': [30000, 40000, 50000, 60000, 55000, 65000],\n",
        "    'Spending_Score': [60, 70, 80, 50, 65, 90]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original Dataset:\")\n",
        "print(df)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 1ï¸â£ NUMEROSITY DATA REDUCTION\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# Example: Aggregation - Grouping customers into age groups\n",
        "df['Age_Group'] = pd.cut(df['Age'], bins=[20, 30, 40, 50, 60], labels=['20-30', '31-40', '41-50', '51-60'])\n",
        "numerosity_reduced = df.groupby('Age_Group').agg({\n",
        "    'Annual_Income': 'mean',\n",
        "    'Spending_Score': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "print(\"\\nNumerosity Reduction (Aggregation by Age Group):\")\n",
        "print(numerosity_reduced)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 2ï¸â£ DIMENSIONALITY DATA REDUCTION\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# Select only numeric columns for PCA\n",
        "features = ['Age', 'Annual_Income', 'Spending_Score']\n",
        "X = df[features]\n",
        "\n",
        "# Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Applying PCA to reduce from 3D â 2D\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
        "dimensionality_reduced = pd.concat([df['Customer_ID'], pca_df], axis=1)\n",
        "\n",
        "print(\"\\nDimensionality Reduction (PCA - 2 Principal Components):\")\n",
        "print(dimensionality_reduced)"
      ],
      "metadata": {
        "id": "xxt10qlcS7J4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/train.csv\", usecols=['annotation_id','annotator','audio'])\n",
        "df"
      ],
      "metadata": {
        "id": "1s3KRViuXF7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "j1-rMtedTBMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.fillna(0)\n",
        "new_df"
      ],
      "metadata": {
        "id": "hhVeMBozTDOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.fillna(method=\"ffill\")\n",
        "new_df"
      ],
      "metadata": {
        "id": "moLDdRUmTE6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.fillna(method=\"bfill\")\n",
        "new_df"
      ],
      "metadata": {
        "id": "GgsoKgI7THPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.interpolate()\n",
        "df"
      ],
      "metadata": {
        "id": "Y92-dtP0TJpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.dropna()\n",
        "new_df"
      ],
      "metadata": {
        "id": "fbftFh5wTLxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.dropna(how='all')\n",
        "new_df"
      ],
      "metadata": {
        "id": "AAMpOBf-TOA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EWcfR2bfTQI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4d7a741"
      },
      "source": [
        "import pandas as pd\n",
        "# Read the CSV file without specifying usecols to inspect the columns\n",
        "df_temp = pd.read_csv(\"/content/train.csv\")\n",
        "print(df_temp.columns)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}